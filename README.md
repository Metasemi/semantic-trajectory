Project for exploring the *semantic trajectories* of text streams, where the motivating cases are GPT prompt/completion/prompt/completion sequences and loom trajectories. For now, the semantic trajectory of a stream is understood to be a sequence of OpenAI semantic embedding vectors, with one embedding vector for each state of the stream as it was generated token by token. So schematically the semantic embedding of a prompt "Mary had" followed by a completion " a little downtime." would be something like: [ sem-embed("Mary"), sem-embed("Mary had"), sem-embed("Mary had a"), sem-embed("Mary had a little"), sem-embed("Mary had a little downtime"), sem-embed("Mary had a little downtime.") ].

There's no documentation yet, but there's only one thing you can do so far, and the code (including the smoke test code at the bottom) should make it pretty obvious how to do it. After you've constructed a SemanticTrajectory instance and called its calculate() method, its delta_mus attribute is a list of vectors, one for each token in the text. The vector at each token is the *difference* between the semantic embedding of the stream up to and including the current token *minus* the immediately prior state of the text without the current token.

More functionality and documentation coming soon!
